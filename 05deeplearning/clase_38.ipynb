{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwmc9WQf9EC2dppag3d/+6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidlealo/sic_ai_2025_jun/blob/main/05deeplearning/clase_38.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proyecto Integrador de AI Engineering con Fashion-MNIST\n",
        "\n",
        "## Descripción General\n",
        "\n",
        "Este proyecto tiene como objetivo simular un flujo de trabajo real en ingeniería de inteligencia artificial utilizando el dataset **Fashion-MNIST**. El ejercicio abarca desde la carga y preprocesamiento de datos hasta la creación de modelos de deep learning, control de calidad con autoencoders, despliegue en API y monitoreo de métricas en producción.\n",
        "\n",
        "Se espera que el estudiante implemente un sistema E2E (End-to-End) que permita clasificar imágenes, validar su calidad y monitorear su desempeño, incluyendo la simulación de un caso de desbalance de clases y su corrección mediante aumento de datos.\n",
        "\n",
        "---\n",
        "\n",
        "## Objetivos de Aprendizaje\n",
        "\n",
        "1. Implementar una **red neuronal convolucional (CNN)** para clasificación multiclase.\n",
        "2. Diseñar y entrenar un **autoencoder** para validación de calidad de imágenes.\n",
        "3. Integrar ambos modelos en una **lógica de decisión** que combine confianza del clasificador y control de calidad.\n",
        "4. Desplegar el modelo como una **API** (FastAPI o Gradio) y probar su uso.\n",
        "5. Simular y analizar métricas de **monitoreo en producción** (latencia, confianza, drift de datos).\n",
        "6. Explorar el uso de **GANs** para aumento de datos en clases minoritarias.\n",
        "\n",
        "---\n",
        "\n",
        "## Requisitos\n",
        "\n",
        "- Google Colab o entorno equivalente con GPU.\n",
        "- Python 3.8+\n",
        "- Librerías:\n",
        "  - tensorflow, tensorflow-datasets\n",
        "  - fastapi, uvicorn, pyngrok (opcional)\n",
        "  - gradio\n",
        "  - scikit-learn, scipy, matplotlib\n",
        "\n",
        "---\n",
        "\n",
        "## Instrucciones Paso a Paso\n",
        "\n",
        "### 1. Configuración del Entorno\n",
        "\n",
        "1. Instalar las dependencias necesarias utilizando pip.\n",
        "2. Configurar la semilla para reproducibilidad.\n",
        "\n",
        "**Explicación:**  \n",
        "Esto garantiza que los resultados de entrenamiento sean replicables, controlando la aleatoriedad de inicialización de pesos y muestreo.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Carga y Preparación de Datos\n",
        "\n",
        "1. Descargar el dataset **Fashion-MNIST** desde `tensorflow_datasets`.\n",
        "2. Normalizar los valores de píxel en el rango [0,1].\n",
        "3. Separar en conjuntos de entrenamiento, validación y prueba.\n",
        "4. Implementar una función para simular desbalance en una clase específica.\n",
        "\n",
        "**Explicación:**  \n",
        "Fashion-MNIST contiene 70,000 imágenes de ropa y calzado en 10 clases. Simular desbalance es útil para reproducir problemas reales de datos donde algunas clases están subrepresentadas.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Modelado\n",
        "\n",
        "**CNN (Clasificación):**\n",
        "- Arquitectura con dos capas convolucionales, pooling, dropout y dos capas densas.\n",
        "- Función de pérdida: `sparse_categorical_crossentropy`.\n",
        "- Optimizador: Adam.\n",
        "\n",
        "**Autoencoder (Control de Calidad):**\n",
        "- Entrenado únicamente con imágenes de una clase designada como \"normal\".\n",
        "- El error de reconstrucción se usa como métrica de calidad.\n",
        "\n",
        "**Explicación:**  \n",
        "La CNN clasifica las imágenes y el autoencoder detecta imágenes atípicas o de baja calidad comparando su reconstrucción con la entrada.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Entrenamiento\n",
        "\n",
        "1. Entrenar la CNN con el conjunto de entrenamiento desbalanceado.\n",
        "2. Entrenar el autoencoder con imágenes de la clase normal.\n",
        "3. Guardar ambos modelos.\n",
        "\n",
        "**Explicación:**  \n",
        "Entrenar por separado permite evaluar cada componente y reutilizarlos en diferentes contextos o lógicas de negocio.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. Evaluación\n",
        "\n",
        "1. Evaluar la CNN en el conjunto de prueba: precisión global, matriz de confusión, precisión por clase.\n",
        "2. Evaluar el autoencoder midiendo el AUC para distinguir la clase normal del resto.\n",
        "3. Visualizar histogramas de error de reconstrucción.\n",
        "\n",
        "**Explicación:**  \n",
        "Esto permite entender la capacidad de generalización del clasificador y la sensibilidad del sistema de QA.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. Lógica de Producción\n",
        "\n",
        "1. Implementar una función de decisión que combine:\n",
        "   - Predicción de la clase y su probabilidad.\n",
        "   - Verificación de calidad mediante el error de reconstrucción del AE.\n",
        "2. Definir umbrales mínimos de confianza y máximos de error de reconstrucción.\n",
        "\n",
        "**Explicación:**  \n",
        "En un sistema real, no basta con predecir, sino que es necesario aceptar o rechazar datos según su calidad y confiabilidad.\n",
        "\n",
        "---\n",
        "\n",
        "### 7. Despliegue del Modelo\n",
        "\n",
        "**Opción 1: FastAPI con Ngrok**\n",
        "- Levantar un servidor local con FastAPI que exponga `/predict` y `/health`.\n",
        "- Conectarlo a Internet con Ngrok para pruebas externas.\n",
        "\n",
        "**Opción 2: Gradio**\n",
        "- Crear una interfaz gráfica simple en el navegador que permita subir imágenes y ver las predicciones y verificaciones de calidad.\n",
        "\n",
        "**Explicación:**  \n",
        "FastAPI simula un despliegue en producción, mientras que Gradio facilita la interacción rápida en entornos de desarrollo.\n",
        "\n",
        "---\n",
        "\n",
        "### 8. Monitoreo en Producción (Simulado)\n",
        "\n",
        "1. Calcular métricas clave: latencia media y p95, confianza media, confianza p10, divergencia KL entre distribuciones de entrenamiento y producción.\n",
        "2. Simular drift utilizando el conjunto de prueba.\n",
        "\n",
        "**Explicación:**  \n",
        "Monitorear el rendimiento del modelo en producción es esencial para detectar degradaciones o cambios en los datos.\n",
        "\n",
        "---\n",
        "\n",
        "### 9. Aumento con GAN (Opcional)\n",
        "\n",
        "1. Entrenar una DCGAN simple para la clase minoritaria.\n",
        "2. Generar imágenes sintéticas y mezclarlas con el conjunto de entrenamiento.\n",
        "3. Reentrenar la CNN y comparar métricas.\n",
        "\n",
        "**Explicación:**  \n",
        "El aumento sintético de datos puede mejorar el rendimiento en clases con pocas muestras.\n",
        "\n",
        "---\n",
        "\n",
        "## Entregables\n",
        "\n",
        "1. Notebook de Google Colab con:\n",
        "   - Código funcional y comentarios claros.\n",
        "   - Ejecución de todas las etapas descritas.\n",
        "2. Informe técnico (Markdown o PDF) que incluya:\n",
        "   - Descripción de la arquitectura y decisiones de diseño.\n",
        "   - Métricas obtenidas.\n",
        "   - Análisis crítico de resultados y mejoras propuestas.\n",
        "3. (Opcional) Dockerfile y Makefile para despliegue local.\n",
        "\n",
        "---\n",
        "\n",
        "## Criterios de Evaluación\n",
        "\n",
        "- **Reproducibilidad (20%)**: Configuración clara, semillas fijas y dependencias documentadas.\n",
        "- **Modelado (25%)**: Arquitecturas justificadas y rendimiento alcanzado.\n",
        "- **Integración (20%)**: Correcta implementación de la lógica de producción.\n",
        "- **Despliegue (15%)**: API o interfaz funcional y documentada.\n",
        "- **Monitoreo (10%)**: Métricas calculadas e interpretadas.\n",
        "- **Calidad del Código (10%)**: Legibilidad, modularidad y comentarios.\n",
        "\n",
        "---\n",
        "\n",
        "## Consideraciones Finales\n",
        "\n",
        "- Se valorará la claridad en la documentación y el orden en el notebook.\n",
        "- El trabajo debe ser desarrollado de forma individual a menos que se indique lo contrario.\n",
        "- Cualquier uso de código externo debe ser referenciado adecuadamente.\n",
        "\n"
      ],
      "metadata": {
        "id": "rTXgdKUsUQOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_qeKWiUCURB1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}