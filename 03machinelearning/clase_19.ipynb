{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEtorr3XOL8ZbuRNG3XllK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidlealo/sic_ai_2025_jun/blob/main/03machinelearning/clase_19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proyecto Integrado de Machine Learning: Modelos Supervisados y No Supervisados\n",
        "\n",
        "## Descripción General\n",
        "\n",
        "Este proyecto tiene como finalidad que los estudiantes apliquen modelos supervisados y no supervisados de aprendizaje automático en un contexto realista, utilizando un conjunto de datos que simula el rendimiento académico de estudiantes. A través del ejercicio, se busca desarrollar habilidades de análisis exploratorio, preparación de datos, entrenamiento de modelos y análisis de resultados para la toma de decisiones basada en datos.\n",
        "\n",
        "## Objetivos\n",
        "\n",
        "1. Aplicar técnicas de preprocesamiento de datos en un conjunto real o simulado.\n",
        "2. Entrenar y evaluar modelos de clasificación supervisada.\n",
        "3. Implementar modelos de clustering no supervisado.\n",
        "4. Analizar, comparar e interpretar los resultados obtenidos de ambos enfoques.\n",
        "5. Generar recomendaciones prácticas para la intervención educativa.\n",
        "\n",
        "---\n",
        "\n",
        "## Requisitos Previos\n",
        "\n",
        "- Conocimiento básico de Python y bibliotecas como `pandas`, `matplotlib`, `seaborn` y `scikit-learn`.\n",
        "- Familiaridad con conceptos fundamentales de Machine Learning.\n",
        "- Capacidad de interpretar métricas de evaluación como accuracy, precisión, recall y F1-score.\n",
        "\n",
        "---\n",
        "\n",
        "## Parte 1: Exploración y Preprocesamiento de Datos\n",
        "\n",
        "1. **Carga de datos**\n",
        "   - Cargar el dataset seleccionado utilizando `pandas`.\n",
        "   - Sugerencia: utilizar el dataset \"Student Performance\" de Kaggle o un dataset simulado con variables académicas y demográficas.\n",
        "\n",
        "2. **Revisión inicial**\n",
        "   - Analizar estructura del dataset, tipos de datos, valores nulos y estadísticas descriptivas.\n",
        "   - Identificar columnas relevantes para el análisis.\n",
        "\n",
        "3. **Visualización de datos**\n",
        "   - Realizar gráficos que ayuden a comprender la distribución y relación entre variables, por ejemplo:\n",
        "     - Boxplot de `final_grade` según `tutoring` (participación en tutorías).\n",
        "     - Histograma de `motivation_score`.\n",
        "     - Diagrama de dispersión entre `study_hours` y `final_grade`.\n",
        "\n",
        "4. **Preprocesamiento**\n",
        "   - Codificar variables categóricas con `LabelEncoder` o `pd.get_dummies()`.\n",
        "   - Normalizar variables numéricas si es necesario.\n",
        "   - Verificar y manejar outliers si corresponde.\n",
        "\n",
        "---\n",
        "\n",
        "## Parte 2: Modelos Supervisados (Clasificación)\n",
        "\n",
        "### Objetivo:\n",
        "Predecir si un estudiante aprobará el curso, a partir de un umbral en la nota final (por ejemplo, >=10).\n",
        "\n",
        "1. **Creación de variable objetivo**\n",
        "   - Crear una nueva variable binaria llamada `approved`:\n",
        "     ```python\n",
        "     df[\"approved\"] = df[\"final_grade\"] >= 10\n",
        "     ```\n",
        "\n",
        "2. **Separación de variables predictoras y objetivo**\n",
        "   - Definir `X` e `y`.\n",
        "   - Dividir los datos en conjunto de entrenamiento y prueba utilizando `train_test_split`.\n",
        "\n",
        "3. **Entrenamiento de modelos**\n",
        "   - Entrenar al menos tres clasificadores diferentes:\n",
        "     - Regresión logística (`LogisticRegression`)\n",
        "     - Vecinos más cercanos (`KNeighborsClassifier`)\n",
        "     - Árbol de decisión (`DecisionTreeClassifier`)\n",
        "\n",
        "4. **Evaluación de modelos**\n",
        "   - Calcular y reportar las siguientes métricas:\n",
        "     - Accuracy\n",
        "     - Precisión\n",
        "     - Recall\n",
        "     - F1-score\n",
        "     - Matriz de confusión\n",
        "\n",
        "5. **Análisis**\n",
        "   - Comparar el desempeño de los modelos.\n",
        "   - Identificar las variables más importantes (en el caso del árbol de decisión).\n",
        "   - Justificar la elección del mejor modelo según los resultados.\n",
        "\n",
        "---\n",
        "\n",
        "## Parte 3: Modelos No Supervisados (Clustering)\n",
        "\n",
        "### Objetivo:\n",
        "Agrupar estudiantes según características similares utilizando técnicas de clustering.\n",
        "\n",
        "1. **Selección de variables**\n",
        "   - Seleccionar variables numéricas relevantes: `study_hours`, `absences`, `motivation_score`, `final_grade`.\n",
        "\n",
        "2. **Reducción de dimensionalidad (opcional)**\n",
        "   - Aplicar PCA si se desea visualizar en 2D o 3D.\n",
        "\n",
        "3. **K-Means**\n",
        "   - Probar diferentes valores de `k`.\n",
        "   - Utilizar el método del codo (elbow method) para seleccionar el número óptimo de clusters.\n",
        "   - Calcular el `silhouette_score` para validar la coherencia de los grupos.\n",
        "\n",
        "4. **Visualización**\n",
        "   - Graficar los clusters en dos dimensiones.\n",
        "   - Analizar las características promedio de cada grupo.\n",
        "   - Asignar etiquetas interpretativas a los perfiles detectados.\n",
        "\n",
        "5. **Comparación con DBSCAN (opcional)**\n",
        "   - Probar el algoritmo `DBSCAN` y comparar con K-Means.\n",
        "   - Analizar la sensibilidad al ruido y detección de outliers.\n",
        "\n",
        "---\n",
        "\n",
        "## Parte 4: Análisis Integrado\n",
        "\n",
        "1. ¿Qué patrones fueron detectados con los modelos supervisados?\n",
        "2. ¿Qué diferencias se observaron en el agrupamiento no supervisado?\n",
        "3. ¿Existen coincidencias entre los estudiantes que reprueban y los clusters de bajo rendimiento?\n",
        "4. ¿Cómo podrían usarse ambos enfoques para diseñar programas de apoyo, tutorías o segmentaciones personalizadas?\n",
        "\n",
        "---\n",
        "\n",
        "## Entregables\n",
        "\n",
        "El proyecto debe incluir:\n",
        "\n",
        "- Código completo, bien documentado, en formato `.ipynb` o `.py`.\n",
        "- Visualizaciones pertinentes con interpretación.\n",
        "- Comparación de resultados entre modelos supervisados y no supervisados.\n",
        "- Tabla comparativa de métricas de evaluación.\n",
        "- Informe escrito con reflexiones finales, conclusiones y posibles aplicaciones.\n",
        "\n",
        "---\n",
        "\n",
        "## Evaluación Sugerida\n",
        "\n",
        "| Criterio                              | Puntos |\n",
        "|---------------------------------------|--------|\n",
        "| Exploración y preprocesamiento        | 20     |\n",
        "| Modelos supervisados y evaluación     | 25     |\n",
        "| Modelos no supervisados y análisis    | 25     |\n",
        "| Análisis integrado y recomendaciones  | 20     |\n",
        "| Claridad en la presentación           | 10     |\n",
        "| **Total**                             | **100**|\n",
        "\n",
        "---\n",
        "\n",
        "## Observaciones Finales\n",
        "\n",
        "Este ejercicio busca simular una situación real en la que se deben tomar decisiones informadas a partir de los datos. Se recomienda trabajar en grupos de 2 a 3 personas y documentar cada etapa con claridad. La calidad del análisis y la interpretación será tan importante como la precisión técnica de los modelos.\n"
      ],
      "metadata": {
        "id": "XhzDZ6iEC8tL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFuYdMREC5cF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Instrucciones para Cargar un Dataset desde Kaggle en Google Colab\n",
        "\n",
        "Este documento describe los pasos necesarios para descargar y utilizar un dataset desde Kaggle directamente en Google Colab, utilizando la autenticación mediante la API de Kaggle.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Crear una cuenta en Kaggle (si no tienes una)\n",
        "\n",
        "Accede al sitio oficial: [https://www.kaggle.com](https://www.kaggle.com)\n",
        "\n",
        "1. Regístrate o inicia sesión.\n",
        "2. Completa la verificación de tu cuenta si es necesario.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Obtener el archivo `kaggle.json` (API Token)\n",
        "\n",
        "1. Entra a tu perfil (clic en tu foto de usuario, esquina superior derecha).\n",
        "2. Selecciona la opción **\"Account\"** en el menú.\n",
        "3. Desplázate hasta la sección **API**.\n",
        "4. Haz clic en **\"Create New API Token\"**.\n",
        "5. Se descargará automáticamente un archivo llamado `kaggle.json`.\n",
        "\n",
        "Este archivo contiene tus credenciales privadas de acceso a la API de Kaggle.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Subir el archivo `kaggle.json` a Google Colab\n",
        "\n",
        "Abre un notebook en Colab y ejecuta la siguiente celda para subir tu archivo:\n",
        "\n",
        "```python\n",
        "from google.colab import files\n",
        "files.upload()  # Selecciona tu archivo kaggle.json cuando se abra el diálogo\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Configurar las credenciales en Colab\n",
        "\n",
        "Ejecuta las siguientes celdas en orden:\n",
        "\n",
        "```python\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "```\n",
        "\n",
        "Esto moverá el archivo a la ubicación adecuada y le asignará los permisos correctos para su uso.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Descargar el dataset desde Kaggle\n",
        "\n",
        "### Opción 1: Student Performance Dataset\n",
        "\n",
        "```python\n",
        "!kaggle datasets download -d spscientist/students-performance-in-exams\n",
        "!unzip students-performance-in-exams.zip\n",
        "```\n",
        "\n",
        "### Opción 2: Student Alcohol Consumption\n",
        "\n",
        "```python\n",
        "!kaggle datasets download -d uciml/student-alcohol-consumption\n",
        "!unzip student-alcohol-consumption.zip\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Cargar el dataset en Pandas\n",
        "\n",
        "### Para el Student Performance Dataset:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"StudentsPerformance.csv\")\n",
        "df.head()\n",
        "```\n",
        "\n",
        "### Para el Student Alcohol Consumption:\n",
        "\n",
        "```python\n",
        "df = pd.read_csv(\"student-mat.csv\", sep=';')\n",
        "df.head()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Consideraciones Finales\n",
        "\n",
        "- No compartas públicamente tu archivo `kaggle.json`. Contiene información confidencial.\n",
        "- Si el archivo descargado tiene varias hojas o tipos de datos, revisa los nombres y estructuras usando `df.info()` y `df.describe()`.\n",
        "\n",
        "Este procedimiento te permite trabajar con datos reales de Kaggle de forma eficiente y reproducible en tus notebooks de Google Colab.\n"
      ],
      "metadata": {
        "id": "HfRLDu45EN5W"
      }
    }
  ]
}