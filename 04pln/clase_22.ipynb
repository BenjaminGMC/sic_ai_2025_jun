{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWc1hc/rvELrGR9VNd7dGF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidlealo/sic_ai_2025_jun/blob/main/04pln/clase_22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clase 22\n",
        "\n",
        "Introducci√≥n PNL"
      ],
      "metadata": {
        "id": "Kg5wnpaF8Q6r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0VT_p9g8KTX"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    \"hola como estas\",\n",
        "    \"hola como te va\",\n",
        "    \"hola que tal\",\n",
        "    \"hoy es un gran d√≠a\",\n",
        "    \"hoy estamos felices\",\n",
        "    \"hoy comemos pastel\",\n",
        "    \"ma√±ana iremos al cine\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Estructura de datos: diccionario de palabras -> siguientes palabras posibles\n",
        "predictor = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "for sentence in corpus:\n",
        "    words = sentence.lower().split()\n",
        "    for i in range(len(words) - 1):\n",
        "        predictor[words[i]][words[i + 1]] += 1\n"
      ],
      "metadata": {
        "id": "UjLTicYW8Ws6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sugerir_siguiente(palabra):\n",
        "    if palabra not in predictor:\n",
        "        return \"Sin sugerencias\"\n",
        "    siguientes = predictor[palabra]\n",
        "    sugerencia = max(siguientes, key=siguientes.get)\n",
        "    return sugerencia\n"
      ],
      "metadata": {
        "id": "rMJz8BfI8aE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entrada = \"hoy\"\n",
        "print(f\"Sugerencia para '{entrada}': {sugerir_siguiente(entrada)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvNIamdk8bwN",
        "outputId": "2d28198e-cb35-462a-ee7c-c929524475ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sugerencia para 'hoy': es\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entrada = \"hola\"\n",
        "print(f\"Sugerencia para '{entrada}': {sugerir_siguiente(entrada)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4mduNKT8c8Z",
        "outputId": "23ddc9cd-ed6d-408f-b4ed-eb946e762e92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sugerencia para 'hola': como\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entrada = \"hoy estamos\"\n",
        "print(f\"Sugerencia para '{entrada}': {sugerir_siguiente(entrada)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5ZvX91w8iNe",
        "outputId": "9b75ff83-e7f3-4f46-90ec-6fdfa593c61a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sugerencia para 'hoy estamos': Sin sugerencias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entrada = input(\"Ingresa una palabra: \")\n",
        "print(f\"Sugerencia para '{entrada}': {sugerir_siguiente(entrada)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhp_xmZmmriu",
        "outputId": "f488a213-2248-427b-b4ad-836c13829bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingresa una palabra: ma√±ana\n",
            "Sugerencia para 'ma√±ana': iremos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NLTK\n",
        "\n",
        "https://www.nltk.org/\n"
      ],
      "metadata": {
        "id": "Su_W3bumnjEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# An√°lisis del archivo `robots.txt` de Wikipedia\n",
        "\n",
        "URL: [https://en.wikipedia.org/robots.txt](https://en.wikipedia.org/robots.txt)\n",
        "\n",
        "---\n",
        "\n",
        "## üß± ESTRUCTURA B√ÅSICA DE UN `robots.txt`\n",
        "\n",
        "La estructura b√°sica de un archivo `robots.txt` tiene reglas con esta sintaxis:\n",
        "\n",
        "```\n",
        "User-agent: [nombre del bot]\n",
        "Disallow: [ruta que no se debe rastrear]\n",
        "Allow: [ruta que s√≠ se puede rastrear]\n",
        "```\n",
        "\n",
        "Opcionalmente puede incluir:\n",
        "\n",
        "- `Sitemap:` ‚Üí Para decir d√≥nde est√° el mapa del sitio.\n",
        "- `Crawl-delay:` ‚Üí Para limitar la frecuencia con la que un bot accede a las p√°ginas.\n",
        "\n",
        "---\n",
        "\n",
        "## üîç CONTENIDO DE `robots.txt` de Wikipedia\n",
        "\n",
        "### 1. Comentarios informativos\n",
        "\n",
        "```txt\n",
        "# Please note: There are multiple Wikimedia projects, including Wikipedia, ...\n",
        "```\n",
        "\n",
        "Estos son **comentarios informativos** para humanos que leen el archivo. Indican que existen m√∫ltiples proyectos de Wikimedia y que cada uno tiene su propio `robots.txt`.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Reglas para todos los bots\n",
        "\n",
        "```txt\n",
        "User-agent: *\n",
        "Disallow: /wiki/Special:\n",
        "Disallow: /w/\n",
        "Disallow: /trap/\n",
        "```\n",
        "\n",
        "**Significado**:\n",
        "\n",
        "- `User-agent: *` ‚Üí Aplica a **todos los bots**.\n",
        "- `Disallow: /wiki/Special:` ‚Üí Bloquea las p√°ginas especiales (como `/wiki/Special:RecentChanges`, etc.).\n",
        "- `Disallow: /w/` ‚Üí Bloquea el acceso al backend del software MediaWiki (como `/w/index.php`, etc.).\n",
        "- `Disallow: /trap/` ‚Üí Bloquea una ruta trampa para bots maliciosos.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Reglas espec√≠ficas para algunos bots\n",
        "\n",
        "```txt\n",
        "User-agent: Googlebot\n",
        "Disallow: /w/\n",
        "```\n",
        "\n",
        "```txt\n",
        "User-agent: Bingbot\n",
        "Disallow: /w/\n",
        "```\n",
        "\n",
        "Estos bloques son similares pero aplican a **bots espec√≠ficos** (como Googlebot y Bingbot). Tambi√©n se les bloquea la carpeta `/w/`.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Crawl-delay para algunos bots\n",
        "\n",
        "```txt\n",
        "User-agent: Slurp\n",
        "Crawl-delay: 1\n",
        "```\n",
        "\n",
        "Esto le dice al bot de Yahoo (Slurp) que espere **al menos 1 segundo entre cada solicitud**.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. Sitemap\n",
        "\n",
        "```txt\n",
        "Sitemap: https://en.wikipedia.org/sitemap.xml\n",
        "```\n",
        "\n",
        "Esto indica a los bots d√≥nde pueden encontrar el **mapa del sitio**, que es un archivo con URLs recomendadas para rastrear.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ RESUMEN\n",
        "\n",
        "- Wikipedia **permite** el acceso a la mayor√≠a de sus p√°ginas de art√≠culos.\n",
        "- **Restringe** el acceso a:\n",
        "  - P√°ginas especiales del sistema (`/wiki/Special:`),\n",
        "  - Rutas del backend del software MediaWiki (`/w/`),\n",
        "  - Carpetas trampa o privadas (`/trap/`).\n",
        "- Define reglas espec√≠ficas para algunos bots populares.\n",
        "- Incluye un `sitemap.xml`.\n"
      ],
      "metadata": {
        "id": "8z666z7rtN4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por ejemplo hay p√°ginas restrictivas para los sistemas automatizados de extraer datos, ejemplo: https://www.instagram.com/robots.txt"
      ],
      "metadata": {
        "id": "zOhE_bGOuAKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Imagen estructura HTML](https://disenowebakus.net/imagenes/articulos/estructura-basica-de-una-pagina-web-en-html.jpg)"
      ],
      "metadata": {
        "id": "jySzkx_t9gCn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descargar informaci√≥n desde sitio web"
      ],
      "metadata": {
        "id": "JeLok8SR9S_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![verbos http](https://gautambiztalkblog.wordpress.com/wp-content/uploads/2015/03/crud.jpg)"
      ],
      "metadata": {
        "id": "KbuXsUeB9pyr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://requests.readthedocs.io/en/latest/"
      ],
      "metadata": {
        "id": "Xx93XRRE96Tl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![C√≥digos de status de requests](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT2oPHcwlYQadHfInt1EeqLdH1TiaPYpV1LZA&s)"
      ],
      "metadata": {
        "id": "mHXzJjri-UHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "res = requests.get('https://en.wikipedia.org/wiki/Machine_learning')\n"
      ],
      "metadata": {
        "id": "xVcU49BetOqu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "id": "4RBVf0lU-d6N",
        "outputId": "194f6508-6c08-40db-b3b4-6810555e1921",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.status_code"
      ],
      "metadata": {
        "id": "E_tU2RYX-jlj",
        "outputId": "51fa47ad-7976-4b6f-cd98-35e0042b2a40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.links"
      ],
      "metadata": {
        "id": "xhKAE5tO-uu4",
        "outputId": "8ebf418f-7c4e-440c-bfd5-ae3f3c50c70c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.json"
      ],
      "metadata": {
        "id": "fh2Clmrf-x7G",
        "outputId": "c48517e7-4c27-4abf-a5dd-2e58f92c1107",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Response.json of <Response [200]>>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>requests.models.Response.json</b><br/>def json(**kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/requests/models.py</a>Returns the json-encoded content of a response, if any.\n",
              "\n",
              ":param \\*\\*kwargs: Optional arguments that ``json.loads`` takes.\n",
              ":raises requests.exceptions.JSONDecodeError: If the response body does not\n",
              "    contain valid json.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 947);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.text"
      ],
      "metadata": {
        "id": "CdWykYYN-0_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://beautiful-soup-4.readthedocs.io/en/latest/"
      ],
      "metadata": {
        "id": "aYOYvJMXAN9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "res = requests.get('https://en.wikipedia.org/wiki/Machine_learning')\n",
        "soup = BeautifulSoup(res.text, 'html.parser')\n"
      ],
      "metadata": {
        "id": "qkfut7Jy_S_Y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup.head()"
      ],
      "metadata": {
        "id": "zbcKOA5LAbc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup.body()"
      ],
      "metadata": {
        "id": "PRfG9qC7AkIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup.b"
      ],
      "metadata": {
        "id": "MjUDyCxABThg",
        "outputId": "948da94a-2e8b-4720-86dc-285f025220dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<b><a href=\"/wiki/Statistical_classification\" title=\"Statistical classification\">classification</a></b>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup.i"
      ],
      "metadata": {
        "id": "p5jXCMeWBdax",
        "outputId": "c9d677dd-9fa9-4312-b03a-2ab3e09b5564",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<i>k</i>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup.a"
      ],
      "metadata": {
        "id": "T5WP9XE4BfiQ",
        "outputId": "5c8079e0-845b-497d-84aa-08221852d32a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<a class=\"mw-jump-link\" href=\"#bodyContent\">Jump to content</a>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find_all('a')"
      ],
      "metadata": {
        "id": "xy4rqgFn_3a9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "res = requests.get('https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico')\n",
        "soup = BeautifulSoup(res.text, 'html.parser')\n",
        "\n",
        "x = soup.find_all('p')\n",
        "text = \"\"\n",
        "\n",
        "for i in range(len(x)):\n",
        "  text += x[i].text.strip() + '\\n'"
      ],
      "metadata": {
        "id": "5MGMfJTzCcYo"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "id": "eDK1dBKOC_n1",
        "outputId": "a201f2dd-1254-45a7-9c3f-69167d1d691b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'El aprendizaje autom√°tico (AA); tambi√©n llamado automatizado, computacional de m√°quinas, o maquinal[1]\\u200b (del ingl√©s machine learning, ML), es el subcampo de las ciencias de la computaci√≥n y una rama de la inteligencia artificial, cuyo objetivo es desarrollar t√©cnicas que permitan que las computadoras aprendan. Se dice que un agente aprende cuando su desempe√±o mejora con la experiencia y mediante el uso de datos; es decir, cuando la habilidad no estaba presente en su genotipo o rasgos de nacimiento.[2]\\u200b \"En el aprendizaje de m√°quinas un computador observa datos, construye un modelo basado en esos datos y utiliza ese modelo a la vez como una hip√≥tesis acerca del mundo y una pieza de software que puede resolver problemas\".[3]\\u200b\\nEn muchas ocasiones el campo de actuaci√≥n del aprendizaje autom√°tico se solapa con el de la estad√≠stica inferencial, ya que las dos disciplinas se basan en el an√°lisis de datos. Sin embargo, el aprendizaje autom√°tico incorpora las preocupaciones de la complejidad computacional de los problemas. Muchos problemas son de clase NP-hard, por lo que gran parte de la investigaci√≥n realizada en aprendizaje autom√°tico est√° enfocada al dise√±o de soluciones factibles a esos problemas. El aprendizaje autom√°tico tambi√©n est√° estrechamente relacionado con el reconocimiento de patrones. El aprendizaje autom√°tico puede ser visto como un intento de automatizar algunas partes del m√©todo cient√≠fico mediante m√©todos matem√°ticos. Por lo tanto es un proceso de inducci√≥n del conocimiento.\\nEl aprendizaje autom√°tico tiene una amplia gama de aplicaciones, incluyendo motores de b√∫squeda, diagn√≥sticos m√©dicos, detecci√≥n de fraude en el uso de tarjetas de cr√©dito, an√°lisis de mercado para los diferentes sectores de actividad, clasificaci√≥n de secuencias de ADN, reconocimiento del habla y del lenguaje escrito, juegos y rob√≥tica.\\nAlgunos sistemas de aprendizaje autom√°tico intentan eliminar toda necesidad de intuici√≥n o conocimiento experto de los procesos de an√°lisis de datos, mientras otros tratan de establecer un marco de colaboraci√≥n entre el experto y la computadora. De todas formas, la intuici√≥n humana no puede ser reemplazada en su totalidad, ya que el dise√±ador del sistema ha de especificar la forma de representaci√≥n de los datos y los m√©todos de manipulaci√≥n y caracterizaci√≥n de los mismos.\\nSin embargo, las computadoras son utilizadas por todo el mundo con fines tecnol√≥gicos muy buenos.\\nEl aprendizaje autom√°tico tiene como resultado un modelo para resolver una tarea dada. Entre los modelos se distinguen[4]\\u200b\\nLos modelos pueden tambi√©n clasificarse como modelos de agrupamiento y modelos de gradiente. Los primeros tratan de dividir el espacio de instancias en grupos. Los segundos, como su nombre lo indican, representan un gradiente en el que se puede diferenciar entre cada instancia. Clasificadores geom√©tricos como las m√°quinas de vectores de apoyo son modelos de gradientes.\\nLos diferentes algoritmos de Aprendizaje Autom√°tico se agrupan en una taxonom√≠a en funci√≥n de la salida de los mismos. Algunos tipos de algoritmos son:\\nEl an√°lisis computacional y de rendimiento de los algoritmos de aprendizaje autom√°tico es una rama de la estad√≠stica conocida como teor√≠a computacional del aprendizaje.\\nEl aprendizaje autom√°tico las personas lo llevamos a cabo de manera autom√°tica ya que es un proceso tan sencillo para nosotros que ni nos damos cuenta de c√≥mo se realiza y todo lo que implica. Desde que nacemos hasta que morimos los seres humanos llevamos a cabo diferentes procesos, entre ellos encontramos el de aprendizaje por medio del cual adquirimos conocimientos, desarrollamos habilidades para analizar y evaluar a trav√©s de m√©todos y t√©cnicas as√≠ como tambi√©n por medio de la experiencia propia. Sin embargo, a las m√°quinas hay que indicarles c√≥mo aprender, ya que si no se logra que una m√°quina sea capaz de desarrollar sus habilidades, el proceso de aprendizaje no se estar√° llevando a cabo, sino que solo ser√° una secuencia repetitiva.\\nEste tipo de aprendizaje usa un √°rbol de decisiones como modelo predictivo. Se mapean observaciones sobre un objeto con conclusiones sobre el valor final de dicho objeto.\\nLos √°rboles son estructuras b√°sicas en la inform√°tica. Los √°rboles de atributos son la base de las decisiones.\\nUna de las dos formas principales de √°rboles de decisiones es la desarrollada por Quinlan de medir la impureza de la entrop√≠a en cada rama, algo que primero desarroll√≥ en el algoritmo ID3 y luego en el C4.5. Otra de las estrategias se basa en el √≠ndice GINI. El algoritmo de CART es una implementaci√≥n de esta estrategia.[6]\\u200b\\nLos algoritmos de reglas de asociaci√≥n procuran descubrir relaciones interesantes entre variables. Entre los m√©todos m√°s conocidos se hallan el algoritmo a priori, el algoritmo Eclat y el algoritmo de patr√≥n frecuente.\\nLos algoritmos gen√©ticos son procesos de b√∫squeda heur√≠stica que simulan la selecci√≥n natural. Usan m√©todos tales como la mutaci√≥n y el cruzamiento para generar nuevas clases que puedan ofrecer una buena soluci√≥n a un problema dado.\\nLas redes de neuronas artificiales (RNA) son un paradigma de aprendizaje autom√°tico inspirado en las neuronas de los sistemas nerviosos de los animales. Se trata de un sistema de enlaces de neuronas que colaboran entre s√≠ para producir un est√≠mulo de salida. Las conexiones tienen pesos num√©ricos que se adaptan seg√∫n la experiencia. De esta manera, las redes neurales se adaptan a un impulso y son capaces de aprender. La importancia de las redes neurales cay√≥ durante un tiempo con el desarrollo de los vectores de soporte y clasificadores lineales, pero volvi√≥ a surgir a finales de la d√©cada de 2000 con la llegada del aprendizaje profundo.\\nLas MVS son una serie de m√©todos de aprendizaje supervisado usados para clasificaci√≥n y regresi√≥n. Los algoritmos de MVS usan un conjunto de ejemplos de formaci√≥n clasificada en dos categor√≠as para construir un modelo que prediga si un nuevo ejemplo pertenece a una u otra de dichas categor√≠as.\\nEl an√°lisis por agrupamiento (clustering en ingl√©s) es la clasificaci√≥n de observaciones en subgrupos ‚Äîclusters‚Äî para que las observaciones en cada grupo se asemejen entre s√≠ seg√∫n ciertos criterios.\\nLas t√©cnicas de agrupamiento hacen inferencias diferentes sobre la estructura de los datos; se gu√≠an usualmente por una medida de similitud espec√≠fica y por un nivel de compactamiento interno (similitud entre los miembros de un grupo) y la separaci√≥n entre los diferentes grupos.\\nEl agrupamiento es un m√©todo de aprendizaje no supervisado y es una t√©cnica muy popular de an√°lisis estad√≠stico de datos.\\nUna red bayesiana, red de creencia o modelo ac√≠clico dirigido es un modelo probabil√≠stico que representa una serie de variables de azar y sus independencias condicionales a trav√©s de un grafo ac√≠clico dirigido. Una red bayesiana puede representar, por ejemplo, las relaciones probabil√≠sticas entre enfermedades y s√≠ntomas. Dados ciertos s√≠ntomas, la red puede usarse para calcular las probabilidades de que ciertas enfermedades est√©n presentes en un organismo. Hay algoritmos eficientes que infieren y aprenden usando este tipo de representaci√≥n.\\nEn el aprendizaje autom√°tico podemos obtener 3 tipos de conocimiento, que son:\\nLos tres tipos se efect√∫an durante un proceso de aprendizaje autom√°tico pero la importancia de cada tipo de conocimiento depende de las caracter√≠sticas de lo que se est√° tratando de aprender.\\nEl aprendizaje es m√°s que una necesidad, es un factor primordial para satisfacer las necesidades de la inteligencia artificial.\\nEl aprendizaje supervisado se caracteriza por contar con informaci√≥n que especifica qu√© conjuntos de datos son satisfactorios para el objetivo del aprendizaje. Un ejemplo podr√≠a ser un software que reconoce si una imagen dada es o no la imagen de un rostro: para el aprendizaje del programa tendr√≠amos que proporcionarle diferentes im√°genes, especificando en el proceso si se trata o no de rostros.\\nEn el aprendizaje no supervisado, en cambio, el programa no cuenta con datos que definan qu√© informaci√≥n es satisfactoria o no. El objetivo principal de estos programas suele ser encontrar patrones que permitan separar y clasificar los datos en diferentes grupos, en funci√≥n de sus atributos. Siguiendo el ejemplo anterior un software de aprendizaje no supervisado no ser√≠a capaz de decirnos si una imagen dada es un rostro o no pero s√≠ podr√≠a, por ejemplo, clasificar las im√°genes entre aquellas que contienen rostros humanos, de animales, o las que no contienen. La informaci√≥n obtenida por un algoritmo de aprendizaje no supervisado debe ser posteriormente interpretada por una persona para darle utilidad.\\nA continuaci√≥n se muestran una serie de temas que podr√≠an formar parte del temario de un curso sobre aprendizaje autom√°tico.\\nEl aprendizaje autom√°tico naci√≥ de la b√∫squeda de inteligencia artificial. Ya en los primeros d√≠as de la IA como disciplina acad√©mica, algunos investigadores se interesaron en hacer que las m√°quinas aprendiesen. Trataron de resolver el problema con diversos m√©todos simb√≥licos, as√≠ como lo que ellos llamaron \\'redes neurales\\' que eran en general perceptrones y otros modelos b√°sicamente basados en modelos lineares generalizados como se conocen en las estad√≠sticas.\\nDesde la d√©cada de 2010, los avances tanto en algoritmos de aprendizaje autom√°tico como en hardware inform√°tico han dado lugar a m√©todos m√°s eficientes para entrenar redes neuronales profundas (un estrecho subdominio particular del aprendizaje autom√°tico) que contienen muchas capas de unidades ocultas no lineales.[7]\\u200b En 2019, las unidades de procesamiento gr√°fico (GPU), a menudo con mejoras espec√≠ficas de IA, hab√≠an desplazado a las CPU como m√©todo dominante para entrenar IA comercial en la nube a gran escala.[8]\\u200b OpenAI calcul√≥ la computaci√≥n de hardware utilizada en los mayores proyectos de aprendizaje profundo desde AlexNet (2012) hasta AlphaZero (2017), y descubri√≥ un aumento de 300 000 veces en la cantidad de computaci√≥n necesaria, con una l√≠nea de tendencia de tiempo de duplicaci√≥n de 3,4 meses.[9]\\u200b[10]\\u200b\\nMuchos lenguajes de programaci√≥n pueden usarse para implementar algoritmos de aprendizaje autom√°tico. Los m√°s populares para 2015 eran R y Python.[11]\\u200b R es muy usado ante todo en el campo acad√©mico, mientras que Python es m√°s popular en la empresa privada.\\nEntre los paquetes de software que incluyen algoritmos de aprendizaje automatizado, se hallan los siguientes:\\nLos algoritmos de aprendizaje autom√°tico a menudo pueden verse afectados por el sesgo que puedan tener los datos (Ver sesgo algoritmico). Por ejemplo, no se podr√°n clasificar todos aquellas entradas de las que no se haya recibido ninguna informaci√≥n en la fase de formaci√≥n. De hecho, cuando la formaci√≥n se realiza con datos clasificados por el ser humano el aprendizaje autom√°tico tiende a crear los mismos sesgos que hay en la sociedad. Algunos ejemplos de esto son cuando en 2015 el algoritmo de Google photos identificaba algunas personas negras como gorilas o en 2016 cuando el bot de Twitter de Microsoft desarroll√≥ comportamientos racistas y machistas con base en observar el tr√°fico de datos en dicha red social. Por este motivo en los √∫ltimos a√±os ha habido una tendencia a desarrollar m√©todos para aumentar la equidad, es decir, para reducir el sesgo en este tipo algoritmos por parte de los expertos en IA. Citando a Fei-fei Li \"La IA no tiene nada de especial. Se inspira en personas, es creada por personas, y lo m√°s importante impacta en las personas. Es una herramienta muy poderosa que tan solo hemos comenzado a entender, y esa es una gran responsabilidad\" [12]\\u200b\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}