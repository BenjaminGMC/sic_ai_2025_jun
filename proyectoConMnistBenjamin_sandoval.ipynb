{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "authors": [
      {
        "name": "ChatGPT - Proyecto Integrador AI Eng con Fashion-MNIST",
        "created": "2025-08-14T23:04:01.174268Z"
      }
    ]
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenjaminGMC/sic_ai_2025_jun/blob/main/proyectoConMnistBenjamin_sandoval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIxWHX8E2Hi9"
      },
      "source": [
        "# Proyecto Integrador: AI Engineering con Fashion-MNIST\n",
        "\n",
        "**Fecha de creación:** 2025-08-14T23:04:01.174268Z\n",
        "\n",
        "Este notebook implementa un sistema E2E (End-to-End) con **Fashion-MNIST** que incluye:\n",
        "- Clasificación con **CNN** (Keras/TensorFlow).\n",
        "- Control de calidad con **Autoencoder** (AE).\n",
        "- **Simulación de desbalance** y corrección con **aumento de datos** (opcional via GAN).\n",
        "- **Despliegue** de inferencia con **FastAPI** y **Gradio**.\n",
        "- **Monitoreo** de métricas de producción (latencia, confianza, drift).\n",
        "\n",
        "> Ejecuta las celdas en orden. Recomendado usar **GPU** en Colab (Runtime → Change runtime type → GPU)."
      ],
      "id": "tIxWHX8E2Hi9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTgk-Vg32Hi-"
      },
      "source": [
        "## 1) Configuración del Entorno\n",
        "Instalamos dependencias (si hace falta en Colab) y fijamos semilla para reproducibilidad."
      ],
      "id": "QTgk-Vg32Hi-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6N0-GHp2Hi-"
      },
      "outputs": [],
      "source": [
        "# (Puede tomar unos minutos en la primera ejecución)\n",
        "!pip -q install tensorflow tensorflow-datasets gradio fastapi uvicorn pyngrok scikit-learn scipy matplotlib\n",
        "\n",
        "import os, random, numpy as np, tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"GPU available:\", len(tf.config.list_physical_devices('GPU')) > 0)"
      ],
      "id": "a6N0-GHp2Hi-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuD6fZ0e2Hi-"
      },
      "source": [
        "## 2) Carga y Preparación de Datos\n",
        "- Cargamos **Fashion-MNIST** desde `tensorflow_datasets`.\n",
        "- Normalizamos a `[0,1]` y separamos train/val/test.\n",
        "- Implementamos una función para **simular desbalance** de una clase."
      ],
      "id": "AuD6fZ0e2Hi-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LE9bERNa2Hi_"
      },
      "outputs": [],
      "source": [
        "CLASS_NAMES = [\n",
        "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "    \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
        "]\n",
        "\n",
        "(ds_train_full, ds_test), ds_info = tfds.load(\n",
        "    \"fashion_mnist\",\n",
        "    split=[\"train\", \"test\"],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "\n",
        "NUM_CLASSES = ds_info.features[\"label\"].num_classes\n",
        "IMG_SIZE = 28\n",
        "\n",
        "# Normalización\n",
        "def normalize_img(image, label):\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    image = tf.expand_dims(image, -1)  # (28,28,1)\n",
        "    return image, label\n",
        "\n",
        "ds_train_full = ds_train_full.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Split train/val\n",
        "VAL_SPLIT = 0.1\n",
        "train_count = ds_info.splits[\"train\"].num_examples\n",
        "val_count = int(train_count * VAL_SPLIT)\n",
        "\n",
        "ds_val = ds_train_full.take(val_count)\n",
        "ds_train = ds_train_full.skip(val_count)\n",
        "\n",
        "# Simular desbalance en una clase\n",
        "def make_imbalanced(ds, target_class=6, minority_ratio=0.2):\n",
        "    \"\"\"\n",
        "    Reduce las muestras de 'target_class' a 'minority_ratio' del total de esa clase.\n",
        "    target_class por defecto = 6 (Shirt).\n",
        "    \"\"\"\n",
        "    by_class = {c: [] for c in range(NUM_CLASSES)}\n",
        "    for img, y in tfds.as_numpy(ds):\n",
        "        by_class[int(y)].append((img, int(y)))\n",
        "    target_samples = by_class[target_class]\n",
        "    keep_n = max(1, int(len(target_samples) * minority_ratio))\n",
        "    random.shuffle(target_samples)\n",
        "    by_class[target_class] = target_samples[:keep_n]\n",
        "    all_samples = []\n",
        "    for c in range(NUM_CLASSES):\n",
        "        all_samples.extend(by_class[c])\n",
        "    random.shuffle(all_samples)\n",
        "    images = np.stack([s[0] for s in all_samples], axis=0)\n",
        "    labels = np.array([s[1] for s in all_samples], dtype=np.int64)\n",
        "    return tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "\n",
        "TARGET_MINORITY_CLASS = 6  # \"Shirt\"\n",
        "MINORITY_RATIO = 0.2\n",
        "ds_train_imbalanced = make_imbalanced(ds_train, target_class=TARGET_MINORITY_CLASS, minority_ratio=MINORITY_RATIO)\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "ds_train_imbalanced = ds_train_imbalanced.shuffle(10_000, seed=SEED).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "ds_val = ds_val.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "ds_test_batched = ds_test.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"Imbalanced train ready. Minority class:\", CLASS_NAMES[TARGET_MINORITY_CLASS])"
      ],
      "id": "LE9bERNa2Hi_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jkGMWvA2Hi_"
      },
      "source": [
        "## 3) Modelado\n",
        "### CNN (Clasificación)\n",
        "Arquitectura: 2 capas Conv2D + MaxPool + Dropout + Dense.\n",
        "\n",
        "### Autoencoder (Control de Calidad)\n",
        "Entrenado como **normal** con imágenes de una clase (por defecto clase 0 = T-shirt/top).\n",
        "El **error de reconstrucción** (MSE) se usa como métrica de calidad."
      ],
      "id": "7jkGMWvA2Hi_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkzFkVkI2Hi_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_cnn(input_shape=(IMG_SIZE, IMG_SIZE, 1), num_classes=NUM_CLASSES):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    model = models.Model(inputs, outputs, name=\"cnn_classifier\")\n",
        "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "def build_autoencoder(input_shape=(IMG_SIZE, IMG_SIZE, 1), latent_dim=32):\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(inp)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    latent = layers.Dense(latent_dim, activation=\"relu\")(x)\n",
        "\n",
        "    x = layers.Dense((IMG_SIZE//4)*(IMG_SIZE//4)*64, activation=\"relu\")(latent)\n",
        "    x = layers.Reshape((IMG_SIZE//4, IMG_SIZE//4, 64))(x)\n",
        "    x = layers.UpSampling2D()(x)\n",
        "    x = layers.Conv2DTranspose(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.UpSampling2D()(x)\n",
        "    out = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "    ae = models.Model(inp, out, name=\"autoencoder\")\n",
        "    ae.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "    return ae\n",
        "\n",
        "cnn = build_cnn()\n",
        "ae = build_autoencoder()\n",
        "cnn.summary()\n",
        "ae.summary()"
      ],
      "id": "AkzFkVkI2Hi_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAVgtypq2Hi_"
      },
      "source": [
        "## 4) Entrenamiento\n",
        "- Entrenamos la **CNN** con el conjunto **desbalanceado**.\n",
        "- Entrenamos el **Autoencoder** sólo con imágenes de la clase **normal**."
      ],
      "id": "OAVgtypq2Hi_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLJ9HUXq2Hi_"
      },
      "outputs": [],
      "source": [
        "EPOCHS_CNN = 8\n",
        "EPOCHS_AE = 8\n",
        "\n",
        "# Entrenamiento CNN\n",
        "history_cnn = cnn.fit(\n",
        "    ds_train_imbalanced,\n",
        "    validation_data=ds_val,\n",
        "    epochs=EPOCHS_CNN\n",
        ")\n",
        "\n",
        "# Extraer solo clase normal para AE (clase 0 por defecto)\n",
        "AE_NORMAL_CLASS = 0\n",
        "def filter_class(ds, class_id):\n",
        "    return ds.filter(lambda x, y: tf.equal(y, class_id)).map(lambda x, y: (x, x))\n",
        "\n",
        "ds_train_normal = filter_class(ds_train_full.map(normalize_img), AE_NORMAL_CLASS)\n",
        "ds_train_normal = ds_train_normal.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "history_ae = ae.fit(ds_train_normal, epochs=EPOCHS_AE)"
      ],
      "id": "TLJ9HUXq2Hi_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoAyzu342Hi_"
      },
      "source": [
        "## 5) Evaluación\n",
        "- Precisión global y **matriz de confusión** para la CNN.\n",
        "- **AUC** del Autoencoder para distinguir clase normal vs. resto.\n",
        "- Histogramas del **error de reconstrucción**."
      ],
      "id": "GoAyzu342Hi_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFe-rTfw2Hi_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# CNN: precisión y matriz de confusión\n",
        "y_true = []\n",
        "y_pred = []\n",
        "y_conf = []\n",
        "\n",
        "for x_batch, y_batch in ds_test_batched:\n",
        "    probs = cnn.predict(x_batch, verbose=0)\n",
        "    preds = probs.argmax(axis=1)\n",
        "    y_true.extend(y_batch.numpy().tolist())\n",
        "    y_pred.extend(preds.tolist())\n",
        "    y_conf.extend(probs.max(axis=1).tolist())\n",
        "\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "print(\"Test Accuracy (CNN):\", acc)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# AE: error de reconstrucción\n",
        "def reconstruction_error(ae, imgs):\n",
        "    recon = ae.predict(imgs, verbose=0)\n",
        "    err = np.mean((recon - imgs.numpy())**2, axis=(1,2,3))\n",
        "    return err\n",
        "\n",
        "errs = []\n",
        "labels_normal_vs_rest = []\n",
        "for x_batch, y_batch in ds_test_batched:\n",
        "    err = reconstruction_error(ae, x_batch)\n",
        "    errs.extend(err.tolist())\n",
        "    labels_normal_vs_rest.extend((y_batch.numpy() == AE_NORMAL_CLASS).astype(int).tolist())\n",
        "\n",
        "errs = np.array(errs)\n",
        "labels_normal_vs_rest = np.array(labels_normal_vs_rest)\n",
        "\n",
        "auc = roc_auc_score(labels_normal_vs_rest, -errs)  # menor error => más \"normal\"\n",
        "print(\"AE AUC (normal vs resto):\", auc)\n",
        "\n",
        "# Visualización: histograma del error\n",
        "plt.figure()\n",
        "plt.hist(errs[labels_normal_vs_rest==1], bins=40, alpha=0.6, label=f\"Normal (clase {AE_NORMAL_CLASS})\")\n",
        "plt.hist(errs[labels_normal_vs_rest==0], bins=40, alpha=0.6, label=\"Resto\")\n",
        "plt.title(\"Error de reconstrucción (AE)\")\n",
        "plt.xlabel(\"MSE\")\n",
        "plt.ylabel(\"Frecuencia\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "cFe-rTfw2Hi_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuWeM1Oc2Hi_"
      },
      "source": [
        "## 6) Lógica de Producción\n",
        "Combinamos **confianza del clasificador** y **calidad (AE)** con umbrales:\n",
        "- `MIN_CONFIDENCE = 0.7`\n",
        "- `MAX_RECON_ERROR` = percentil 95 del error en la clase normal."
      ],
      "id": "wuWeM1Oc2Hi_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taKyhYX22Hi_"
      },
      "outputs": [],
      "source": [
        "# Calibramos MAX_RECON_ERROR con percentil 95 en la clase normal del set de test\n",
        "normal_errs = []\n",
        "for x_batch, y_batch in ds_test_batched:\n",
        "    mask = (y_batch.numpy() == AE_NORMAL_CLASS)\n",
        "    if np.any(mask):\n",
        "        xb = x_batch.numpy()[mask]\n",
        "        xb = tf.convert_to_tensor(xb)\n",
        "        e = reconstruction_error(ae, xb)\n",
        "        normal_errs.extend(e.tolist())\n",
        "\n",
        "MAX_RECON_ERROR = float(np.percentile(normal_errs, 95)) if normal_errs else 0.02\n",
        "MIN_CONFIDENCE = 0.7\n",
        "\n",
        "print(\"MAX_RECON_ERROR (p95 normal):\", MAX_RECON_ERROR)\n",
        "print(\"MIN_CONFIDENCE:\", MIN_CONFIDENCE)\n",
        "\n",
        "def decide(image_tensor):\n",
        "    probs = cnn.predict(tf.expand_dims(image_tensor, 0), verbose=0)[0]\n",
        "    pred = int(np.argmax(probs))\n",
        "    conf = float(np.max(probs))\n",
        "    rec = ae.predict(tf.expand_dims(image_tensor, 0), verbose=0)[0]\n",
        "    recon_error = float(np.mean((rec - image_tensor.numpy())**2))\n",
        "    accept = (conf >= MIN_CONFIDENCE) and (recon_error <= MAX_RECON_ERROR)\n",
        "    reason = []\n",
        "    if conf < MIN_CONFIDENCE: reason.append(\"Baja confianza\")\n",
        "    if recon_error > MAX_RECON_ERROR: reason.append(\"Alta anomalía / baja calidad\")\n",
        "    reason = \", \".join(reason) if reason else \"OK\"\n",
        "    return {\n",
        "        \"accepted\": bool(accept),\n",
        "        \"pred_class\": int(pred),\n",
        "        \"pred_label\": CLASS_NAMES[pred],\n",
        "        \"confidence\": conf,\n",
        "        \"reconstruction_error\": recon_error,\n",
        "        \"reason\": reason\n",
        "    }\n",
        "\n",
        "# Demo con una muestra del test\n",
        "for x_batch, y_batch in ds_test_batched.take(1):\n",
        "    sample = x_batch[0]\n",
        "    print(decide(sample))"
      ],
      "id": "taKyhYX22Hi_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_wIQWwA2Hi_"
      },
      "source": [
        "## 7) Despliegue del Modelo\n",
        "### Opción A: **FastAPI** + **Ngrok** (opcional)\n",
        "Guarda modelos y ejecuta el servidor. En Colab puedes tunelar el puerto 8000 con `pyngrok`."
      ],
      "id": "e_wIQWwA2Hi_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_0jy5-92Hi_"
      },
      "outputs": [],
      "source": [
        "import os, numpy as np, tensorflow as tf\n",
        "MODEL_DIR = \"/content/models\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "cnn.save(os.path.join(MODEL_DIR, \"cnn.keras\"))\n",
        "ae.save(os.path.join(MODEL_DIR, \"ae.keras\"))\n",
        "np.save(os.path.join(MODEL_DIR, \"max_recon_error.npy\"), np.array([MAX_RECON_ERROR]))\n",
        "print(\"Modelos guardados en\", MODEL_DIR)\n",
        "\n",
        "FASTAPI_CODE = \"\"\"\n",
        "import io, base64, numpy as np, uvicorn, tensorflow as tf\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from PIL import Image\n",
        "\n",
        "CLASS_NAMES = [\n",
        "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "    \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
        "]\n",
        "MIN_CONFIDENCE = 0.7\n",
        "\n",
        "cnn = tf.keras.models.load_model('/content/models/cnn.keras', compile=False)\n",
        "ae  = tf.keras.models.load_model('/content/models/ae.keras', compile=False)\n",
        "try:\n",
        "    MAX_RECON_ERROR = float(np.load('/content/models/max_recon_error.npy'))\n",
        "except Exception:\n",
        "    MAX_RECON_ERROR = 0.02\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "class PredictRequest(BaseModel):\n",
        "    image_b64: str\n",
        "\n",
        "def preprocess(image_bytes):\n",
        "    img = Image.open(io.BytesIO(image_bytes)).convert('L').resize((28,28))\n",
        "    arr = np.array(img).astype('float32')/255.0\n",
        "    arr = np.expand_dims(arr, -1)\n",
        "    return tf.convert_to_tensor(arr)\n",
        "\n",
        "@app.get('/health')\n",
        "def health():\n",
        "    return {'status': 'ok'}\n",
        "\n",
        "@app.post('/predict')\n",
        "def predict(req: PredictRequest):\n",
        "    image_bytes = base64.b64decode(req.image_b64)\n",
        "    x = preprocess(image_bytes)\n",
        "    probs = cnn.predict(tf.expand_dims(x, 0), verbose=0)[0]\n",
        "    pred = int(np.argmax(probs))\n",
        "    conf = float(np.max(probs))\n",
        "    rec = ae.predict(tf.expand_dims(x, 0), verbose=0)[0]\n",
        "    recon_error = float(np.mean((rec - x.numpy())**2))\n",
        "    accept = (conf >= MIN_CONFIDENCE) and (recon_error <= MAX_RECON_ERROR)\n",
        "    reason = []\n",
        "    if conf < MIN_CONFIDENCE: reason.append('Baja confianza')\n",
        "    if recon_error > MAX_RECON_ERROR: reason.append('Alta anomalía')\n",
        "    reason = ', '.join(reason) if reason else 'OK'\n",
        "    return {\n",
        "        'accepted': bool(accept),\n",
        "        'pred_class': int(pred),\n",
        "        'pred_label': CLASS_NAMES[pred],\n",
        "        'confidence': conf,\n",
        "        'reconstruction_error': recon_error,\n",
        "        'reason': reason\n",
        "    }\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    uvicorn.run(app, host='0.0.0.0', port=8000)\n",
        "\"\"\"\n",
        "with open(\"/content/app_fastapi.py\", \"w\") as f:\n",
        "    f.write(FASTAPI_CODE)\n",
        "\n",
        "print(\"Escribe en una celda aparte: !python app_fastapi.py\")"
      ],
      "id": "g_0jy5-92Hi_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmWWCwYZ2Hi_"
      },
      "source": [
        "### Opción B: **Gradio**"
      ],
      "id": "MmWWCwYZ2Hi_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMgWJUcw2Hi_"
      },
      "outputs": [],
      "source": [
        "import gradio as gr, numpy as np, tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "loaded_cnn = tf.keras.models.load_model(\"/content/models/cnn.keras\", compile=False)\n",
        "loaded_ae  = tf.keras.models.load_model(\"/content/models/ae.keras\", compile=False)\n",
        "CLASS_NAMES = [\n",
        "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "    \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
        "]\n",
        "try:\n",
        "    MAX_RECON_ERROR = float(np.load(\"/content/models/max_recon_error.npy\"))\n",
        "except Exception:\n",
        "    MAX_RECON_ERROR = 0.02\n",
        "MIN_CONFIDENCE = 0.7\n",
        "\n",
        "def classify_and_qc(img: Image.Image):\n",
        "    img = img.convert(\"L\").resize((28,28))\n",
        "    arr = np.array(img).astype(\"float32\")/255.0\n",
        "    arr = np.expand_dims(arr, -1)\n",
        "    x = tf.convert_to_tensor(arr)\n",
        "\n",
        "    probs = loaded_cnn.predict(tf.expand_dims(x, 0), verbose=0)[0]\n",
        "    pred = int(np.argmax(probs))\n",
        "    conf = float(np.max(probs))\n",
        "\n",
        "    rec = loaded_ae.predict(tf.expand_dims(x, 0), verbose=0)[0]\n",
        "    recon_error = float(np.mean((rec - x.numpy())**2))\n",
        "\n",
        "    accept = (conf >= MIN_CONFIDENCE) and (recon_error <= MAX_RECON_ERROR)\n",
        "    out = {\n",
        "        \"Predicción\": CLASS_NAMES[pred],\n",
        "        \"Confianza\": conf,\n",
        "        \"Recon_error\": recon_error,\n",
        "        \"Aceptado\": bool(accept)\n",
        "    }\n",
        "    return out\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=classify_and_qc,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=\"label\",\n",
        "    title=\"Fashion-MNIST: Clasificación + Control de Calidad (AE)\",\n",
        "    description=\"Sube una imagen de prenda (28x28 escala de grises funciona mejor).\"\n",
        ")\n",
        "print(\"Ejecuta: demo.launch(share=True)\")"
      ],
      "id": "NMgWJUcw2Hi_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE6PP8RW2Hi_"
      },
      "source": [
        "## 8) Monitoreo en Producción (Simulado)\n",
        "Calculamos métricas: latencia media y p95, confianza media y p10, KL(train || prod)."
      ],
      "id": "cE6PP8RW2Hi_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-5sEftF2Hi_"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from scipy.stats import entropy\n",
        "import numpy as np\n",
        "\n",
        "# Estimar distribución de entrenamiento (a partir de labels en ds_train_imbalanced)\n",
        "train_labels = []\n",
        "for x, y in ds_train_imbalanced.unbatch().take(5000):\n",
        "    train_labels.append(int(y.numpy()))\n",
        "train_hist = np.bincount(train_labels, minlength=NUM_CLASSES) + 1e-9\n",
        "train_dist = train_hist / train_hist.sum()\n",
        "\n",
        "confs_prod, preds_prod, latencies = [], [], []\n",
        "\n",
        "for x_batch, y_batch in ds_test_batched:\n",
        "    t0 = time.time()\n",
        "    probs = cnn.predict(x_batch, verbose=0)\n",
        "    latencies.append(time.time() - t0)\n",
        "    preds = probs.argmax(axis=1)\n",
        "    preds_prod.extend(preds.tolist())\n",
        "    confs_prod.extend(probs.max(axis=1).tolist())\n",
        "\n",
        "lat_mean = float(np.mean(latencies))\n",
        "lat_p95  = float(np.percentile(latencies, 95))\n",
        "conf_mean = float(np.mean(confs_prod))\n",
        "conf_p10  = float(np.percentile(confs_prod, 10))\n",
        "\n",
        "prod_hist = np.bincount(preds_prod, minlength=NUM_CLASSES) + 1e-9\n",
        "prod_dist = prod_hist / prod_hist.sum()\n",
        "kl_div = float(entropy(train_dist, prod_dist))  # KL(train || prod)\n",
        "\n",
        "print({\n",
        "    \"lat_mean_s\": lat_mean,\n",
        "    \"lat_p95_s\": lat_p95,\n",
        "    \"conf_mean\": conf_mean,\n",
        "    \"conf_p10\": conf_p10,\n",
        "    \"KL(train||prod)\": kl_div\n",
        "})"
      ],
      "id": "u-5sEftF2Hi_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL_FYk4r2HjA"
      },
      "source": [
        "## 9) Aumento con DCGAN (Opcional)\n",
        "Entrenamos una **DCGAN** simple para la clase minoritaria y reentrenamos la CNN con datos sintéticos."
      ],
      "id": "sL_FYk4r2HjA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdMu7c6A2HjA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models, optimizers\n",
        "import numpy as np, tensorflow as tf\n",
        "\n",
        "MINORITY_CLASS = TARGET_MINORITY_CLASS\n",
        "\n",
        "minority_imgs = []\n",
        "for x, y in ds_train_imbalanced.unbatch().take(60000):\n",
        "    if int(y.numpy()) == MINORITY_CLASS:\n",
        "        minority_imgs.append(x.numpy())\n",
        "minority_imgs = np.array(minority_imgs, dtype=\"float32\")\n",
        "print(\"Minority images:\", minority_imgs.shape)\n",
        "\n",
        "LATENT_DIM = 64\n",
        "\n",
        "def build_generator():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(LATENT_DIM,)),\n",
        "        layers.Dense(7*7*128),\n",
        "        layers.Reshape((7,7,128)),\n",
        "        layers.Conv2DTranspose(64, 4, strides=2, padding=\"same\", activation=\"relu\"),\n",
        "        layers.Conv2DTranspose(32, 4, strides=2, padding=\"same\", activation=\"relu\"),\n",
        "        layers.Conv2D(1, 3, padding=\"same\", activation=\"sigmoid\"),\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_discriminator():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(28,28,1)),\n",
        "        layers.Conv2D(32, 3, strides=2, padding=\"same\", activation=\"relu\"),\n",
        "        layers.Conv2D(64, 3, strides=2, padding=\"same\", activation=\"relu\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ])\n",
        "    model.compile(optimizer=optimizers.Adam(1e-4), loss=\"binary_crossentropy\")\n",
        "    return model\n",
        "\n",
        "gen = build_generator()\n",
        "disc = build_discriminator()\n",
        "disc.trainable = True\n",
        "\n",
        "gan_input = layers.Input(shape=(LATENT_DIM,))\n",
        "gan_output = disc(gen(gan_input))\n",
        "gan = models.Model(gan_input, gan_output)\n",
        "disc.trainable = False\n",
        "gan.compile(optimizer=optimizers.Adam(1e-4), loss=\"binary_crossentropy\")\n",
        "\n",
        "EPOCHS_GAN = 3\n",
        "BATCH_GAN = 64\n",
        "steps_per_epoch = max(1, len(minority_imgs)//BATCH_GAN)\n",
        "\n",
        "for epoch in range(EPOCHS_GAN):\n",
        "    for step in range(steps_per_epoch):\n",
        "        if len(minority_imgs) == 0:\n",
        "            break\n",
        "        # Discriminator\n",
        "        idx = np.random.randint(0, len(minority_imgs), BATCH_GAN)\n",
        "        real = minority_imgs[idx]\n",
        "        z = np.random.normal(size=(BATCH_GAN, LATENT_DIM)).astype(\"float32\")\n",
        "        fake = gen.predict(z, verbose=0)\n",
        "        x = np.concatenate([real, fake], axis=0)\n",
        "        y = np.concatenate([np.ones((BATCH_GAN,1)), np.zeros((BATCH_GAN,1))], axis=0)\n",
        "        disc.trainable = True\n",
        "        d_loss = disc.train_on_batch(x, y)\n",
        "        # Generator\n",
        "        z = np.random.normal(size=(BATCH_GAN, LATENT_DIM)).astype(\"float32\")\n",
        "        y_gan = np.ones((BATCH_GAN,1))\n",
        "        disc.trainable = False\n",
        "        g_loss = gan.train_on_batch(z, y_gan)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS_GAN} - d_loss: {d_loss:.4f} - g_loss: {g_loss:.4f}\")\n",
        "\n",
        "# Generar sintéticos y reentrenar\n",
        "N_SYN = min(2000, 5*len(minority_imgs)) if len(minority_imgs)>0 else 0\n",
        "if N_SYN > 0:\n",
        "    z = np.random.normal(size=(N_SYN, LATENT_DIM)).astype(\"float32\")\n",
        "    synth = gen.predict(z, verbose=0)\n",
        "    X_aug = np.concatenate([minority_imgs, synth], axis=0)\n",
        "    y_aug = np.full((X_aug.shape[0],), MINORITY_CLASS, dtype=\"int32\")\n",
        "\n",
        "    X_rest, y_rest = [], []\n",
        "    for x, y in ds_train_full.unbatch().take(60000):\n",
        "        if int(y.numpy()) != MINORITY_CLASS:\n",
        "            X_rest.append((tf.cast(x, tf.float32)/255.0).numpy())\n",
        "            y_rest.append(int(y.numpy()))\n",
        "    X_rest = np.array(X_rest, dtype=\"float32\")\n",
        "    y_rest = np.array(y_rest, dtype=\"int32\")\n",
        "\n",
        "    X_train_bal = np.concatenate([X_rest, X_aug], axis=0)\n",
        "    y_train_bal = np.concatenate([y_rest, y_aug], axis=0)\n",
        "\n",
        "    def build_cnn_local():\n",
        "        from tensorflow.keras import layers, models\n",
        "        inputs = layers.Input(shape=(28,28,1))\n",
        "        x = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
        "        x = layers.MaxPooling2D()(x)\n",
        "        x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "        x = layers.MaxPooling2D()(x)\n",
        "        x = layers.Dropout(0.25)(x)\n",
        "        x = layers.Flatten()(x)\n",
        "        x = layers.Dense(128, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(0.5)(x)\n",
        "        outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "        model = models.Model(inputs, outputs)\n",
        "        model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "        return model\n",
        "\n",
        "    cnn_bal = build_cnn_local()\n",
        "    cnn_bal.fit(\n",
        "        tf.data.Dataset.from_tensor_slices((X_train_bal, y_train_bal)).shuffle(20000).batch(128),\n",
        "        epochs=4,\n",
        "        validation_data=ds_val\n",
        "    )\n",
        "\n",
        "    # Evaluación comparativa\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    def eval_model(m):\n",
        "        y_true, y_pred = [], []\n",
        "        for xb, yb in ds_test_batched:\n",
        "            probs = m.predict(xb, verbose=0)\n",
        "            y_true.extend(yb.numpy().tolist())\n",
        "            y_pred.extend(probs.argmax(axis=1).tolist())\n",
        "        return accuracy_score(y_true, y_pred)\n",
        "\n",
        "    # Se asume 'acc' calculado previamente para la CNN base\n",
        "    base_acc = acc\n",
        "    bal_acc = eval_model(cnn_bal)\n",
        "    print({\"base_acc\": base_acc, \"augmented_acc\": bal_acc})\n",
        "else:\n",
        "    print(\"No se pudo entrenar DCGAN o no hay suficientes muestras minoritarias.\")"
      ],
      "id": "WdMu7c6A2HjA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFW-7WSm2HjA"
      },
      "source": [
        "## 10) Guardado de Modelos"
      ],
      "id": "PFW-7WSm2HjA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPgbyy0C2HjA"
      },
      "outputs": [],
      "source": [
        "cnn.save(\"/content/models/cnn_final.keras\")\n",
        "ae.save(\"/content/models/ae_final.keras\")\n",
        "print(\"Modelos guardados en /content/models\")"
      ],
      "id": "sPgbyy0C2HjA"
    }
  ]
}